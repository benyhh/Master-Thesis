\babel@toc {USenglish}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {table}{\numberline {2.1}{\ignorespaces The terms in the analytical model. \textcolor {red}{Table not complete.} \relax }}{19}{table.caption.15}%
\contentsline {table}{\numberline {2.2}{\ignorespaces Extract of raw data obtained with NFLASH230. The data file also includes the source, which is irrelevant to this project.\relax }}{20}{table.caption.16}%
\contentsline {table}{\numberline {2.3}{\ignorespaces The frequency in data points per minute of different variables in the monitor database.\relax }}{23}{table.caption.26}%
\contentsline {table}{\numberline {2.4}{\ignorespaces The number of times each instrument was used for a pointing scan in $2022$. There are $8847$ scans in total.\relax }}{27}{table.caption.34}%
\contentsline {table}{\numberline {2.5}{\ignorespaces Extract from a tiltmeter dump file.\relax }}{28}{table.caption.35}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {table}{\numberline {4.1}{\ignorespaces This table presents a list of parameters we sampled during hyperparameter tuning for the pointing scan classifier. The table includes names, sampled distributions and corresponding ranges, and parameter values for the best model.\relax }}{42}{table.caption.43}%
\contentsline {table}{\numberline {4.2}{\ignorespaces This table shows the tiltmeter dump file containing the telescope state flag, and how we find the start ($\Delta = 1$) and end ($\Delta = -1$) of a scan.\relax }}{44}{table.caption.46}%
\contentsline {table}{\numberline {4.3}{\ignorespaces This table presents a list of parameters we sampled during hyperparameter tuning for the pointing correction model. The table includes names, sampled distributions, and corresponding ranges.\relax }}{50}{table.caption.57}%
\contentsline {table}{\numberline {4.4}{\ignorespaces This table presents a list of parameters we sampled during hyperparameter tuning for the base pointing model. The table includes names, the distribution we sampled from, and corresponding ranges.\relax }}{53}{table.caption.62}%
\addvspace {10\p@ }
\contentsline {table}{\numberline {5.1}{\ignorespaces Validation and test performance for Case 1 and 2 for the model trained on all data. The performance is given for the model complexity $k$ that yields the best results on the validation data for the given fold.\relax }}{55}{table.caption.64}%
\contentsline {table}{\numberline {5.2}{\ignorespaces why no work}}{55}{table.caption.65}%
\contentsline {table}{\numberline {5.3}{\ignorespaces Resulting RMS ratio (see Eq. \eqref {eq:mean_rms_compared}) on unseen test sets from case $1$ and $2$ (see Figure \ref {fig:datasplit_cases}) for the NFLASH230 model, using different number of features $k$ in the model.\relax }}{56}{table.caption.66}%
\contentsline {table}{\numberline {5.4}{\ignorespaces Resulting RMS ratio (see Eq. \eqref {eq:mean_rms_compared}) on unseen test sets from case $1$ and $2$ (see Figure \ref {fig:datasplit_cases}) for the model predicting offsets from all instruments, using different number of features $k$ in the model.\relax }}{56}{table.caption.67}%
\contentsline {table}{\numberline {5.5}{\ignorespaces Mean RMS ratio on test set (mean over values in Tables \ref {tab:results_minval_val_test_days_04_n230} and \ref {tab:results_minval_val_test_days_04_all}).\relax }}{57}{table.caption.68}%
\contentsline {table}{\numberline {5.6}{\ignorespaces The RMS of the pointing model on the test set in each fold for all neural network architectures. The different architectures are described in Figure \ref {fig:nn_architecture}.\relax }}{66}{table.caption.73}%
\contentsline {table}{\numberline {5.7}{\ignorespaces Hyperparameters used in the best-performing model for each architecture.\relax }}{66}{table.caption.74}%
\contentsline {table}{\numberline {5.8}{\ignorespaces Features used in the best-performing model for each architecture.\relax }}{67}{table.caption.75}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {table}{\numberline {A.1}{\ignorespaces Performance when choosing min validation for the last fold.\relax }}{73}{table.caption.76}%
\contentsline {table}{\numberline {A.2}{\ignorespaces Performance when choosing min validation for each fold. Train/val split on days. Test size $0.43$.\relax }}{73}{table.caption.77}%
\contentsline {table}{\numberline {A.4}{\ignorespaces All\relax }}{75}{table.caption.78}%
\contentsline {table}{\numberline {A.5}{\ignorespaces NFLASH230\relax }}{76}{table.caption.79}%
\contentsline {table}{\numberline {A.6}{\ignorespaces Validation and test performance for Case 2, all instruments left and nflash230 right. Performance when choosing the number of features showing best performance.\relax }}{76}{table.caption.80}%
\contentsline {table}{\numberline {A.7}{\ignorespaces Validation and test performance for Case 1 and 2, all instruments. Performance when choosing the model complexity that yields the best results on the validation set for the given fold.\relax }}{77}{table.caption.81}%
\contentsline {table}{\numberline {A.8}{\ignorespaces Validation and test performance for Case 1 and 2, only NFLASH230. Performance when choosing the model complexity that yields the best results on the validation set for the given fold.\relax }}{77}{table.caption.82}%
\contentsline {table}{\numberline {A.9}{\ignorespaces Features with Spearman's rank correlation $\geq 0.1$ to either one of the target values.\relax }}{78}{table.caption.83}%
\contentsline {table}{\numberline {A.10}{\ignorespaces Features with Pearson's correlation $\geq 0.1$ to either one of the target values.\relax }}{78}{table.caption.84}%
\addvspace {10\p@ }
\contentsline {table}{\numberline {B.1}{\ignorespaces \textbf {Original:} Example from the dataset of the observed pointing offsets and the corrections applied during the pointing scan. \textbf {Transformed:} Pointing offsets and corrections according to equations \eqref {eq:ca_tilde}, \eqref {eq:ie_tilde}, \eqref {eq:off_az_tilde}, and \eqref {eq:off_el_tilde}.\relax }}{80}{table.caption.85}%
